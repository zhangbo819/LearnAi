import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
import os
import zipfile
from tensorflow.keras.preprocessing import image
import pathlib

url = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'
zip_path = tf.keras.utils.get_file('cats_and_dogs_filtered.zip', origin=url, extract=False)

# è§£å‹ zip æ–‡ä»¶
with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall(os.path.dirname(zip_path))

# è®¾ç½®æ•°æ®è·¯å¾„
base_dir = os.path.join(os.path.dirname(zip_path), 'cats_and_dogs_filtered')
train_dir = os.path.join(base_dir, 'train')
validation_dir = os.path.join(base_dir, 'validation')

# 2ï¸âƒ£ åŠ è½½å›¾åƒæ•°æ®é›†
BATCH_SIZE = 32
IMG_SIZE = (180, 180)

train_ds = tf.keras.utils.image_dataset_from_directory(
    train_dir,
    shuffle=True,
    batch_size=BATCH_SIZE,
    image_size=IMG_SIZE
)

val_ds = tf.keras.utils.image_dataset_from_directory(
    validation_dir,
    shuffle=True,
    batch_size=BATCH_SIZE,
    image_size=IMG_SIZE
)

# 3ï¸âƒ£ é¢„å¤„ç†ä¼˜åŒ–ï¼šç¼“å­˜å’Œé¢„å–
AUTOTUNE = tf.data.AUTOTUNE
train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)
val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)

# 4ï¸âƒ£ æ„å»º CNN æ¨¡å‹
model = tf.keras.Sequential([
    tf.keras.layers.Rescaling(1./255, input_shape=(180, 180, 3)),
    tf.keras.layers.Conv2D(16, 3, padding='same', activation='relu'),
    tf.keras.layers.MaxPooling2D(),
    tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu'),
    tf.keras.layers.MaxPooling2D(),
    tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu'),
    tf.keras.layers.MaxPooling2D(),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dense(1)  # äºŒåˆ†ç±»
])

# 5ï¸âƒ£ ç¼–è¯‘æ¨¡å‹
model.compile(optimizer='adam',
              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),
              metrics=['accuracy'])

# 6ï¸âƒ£ è®­ç»ƒæ¨¡å‹
EPOCHS = 5
history = model.fit(train_ds, validation_data=val_ds, epochs=EPOCHS)

# 7ï¸âƒ£ å¯è§†åŒ–è®­ç»ƒè¿‡ç¨‹
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Val Accuracy')
plt.legend(loc='lower right')
plt.title('Training and Validation Accuracy')
plt.show()

# 8ï¸âƒ£ ä¿å­˜æ¨¡å‹
model.save('cat_dog_cnn_model.h5')

# 9ï¸âƒ£ è¯†åˆ«æœ¬åœ°å›¾åƒ
def predict_image(img_path):
    img = image.load_img(img_path, target_size=(180, 180))
    img_array = image.img_to_array(img)
    img_array = tf.expand_dims(img_array, 0)

    predictions = model.predict(img_array)
    score = tf.nn.sigmoid(predictions[0][0])
    label = "ğŸ¶ ç‹—" if score > 0.5 else "ğŸ± çŒ«"
    print(f"è¯†åˆ«ç»“æœ: {label}ï¼Œç½®ä¿¡åº¦ï¼š{score.numpy():.2f}")

# ğŸ§ª æµ‹è¯•ä¸€å¼ å›¾ç‰‡ï¼ˆæ”¾ä½ è‡ªå·±çš„å›¾ç‰‡è·¯å¾„ï¼‰
predict_image("your_cat_or_dog.jpg")
